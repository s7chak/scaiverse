<p><i>Past the hype, what it is and what it can do.</i></p>
<br />
<p>How humans created the makings of an artificial mind.</p>
<br />
<br/>
<div
  className="scpost-img"
  style="display: flex; align-items: center; justify-content: center"
>
  <img
    style="border-radius: 5px"
    src="https://github.com/s7chak/Blogage/blob/master/pix/scaiverse-blogs/ai-human.jpg?raw=true"
    alt="The next mind"
  />
</div>
<br/>
<h2 style="font-size: 24px;"><b>What is this thing?</b></h2>
<br />
<p>
  I am in no sense an expert on language models, coming from the land of software merely dipping my feet in the ocean of machine learning. But here is what I understood of the current state of this "artificial intelligence" kraken. There are impressive, meh and real ugly implicative parts to the creature, so I want to begin by defining what this is. Four ideas led to this and here they are:<br />
  Artificial Intelligence is this broad domain of producing intelligent behavior from inorganic, non-living material or machines or silicon chips. It says nothing about how the intelligence may be arrived at, it could be machine learning, computer vision, complex programming or any other way we devise make machines beat us in chess.<br /><br/>
  Machine learning is the most common methodology used to achieve this intelligence and it is a essentially an optimization problem. Funny way to oversimplify a whole field, you might think, but at the heart of all models and algorithms that qualify as machine learning, there is some optimization going on to minimize the error in predicting some numbers, or training. In this field, we feed our silicon buddies loads of data to understand patterns in it. When data in the form of numbers is not available, say text or images, those are coded as numbers regardless and fed to a model to learn patterns in the numbers representing other things to humans. And as the names suggest supervised learning happens with labeled or marked targets, and unsupervised is the algorithm let loose on these numbers to find patterns on its own.<br /><br/>
  This branch of computer science began its journey with its core in mathematics like linear regressions, matrix algebra, gradient descent or the idea of iteratively reducing error in estimation of a function. Many algorithms were born in this phase like decision tree regressors, boosted decision trees which took the average of many tree regressors, a whole array of nuanced classifiers like Support Vector machines, Naive-Bayes and others. These were explanable in the sense we could tell why a certain prediction was thrown out of a model, individual importances of each input feature could be extracted from these "shallow" algorithms. Then came the neuron and neural networks with their own round of enhancements to keep getting better at predicting numbers. Essentially a neuron is a single unit that is at its core a function estimator, they are combined in layers with weights on each neuron to approximate a complex function. It is because of the layers this is known as deep learning and with it we lost explanability. Most aspects of the prediction process in a large enough neural network is difficult to visualize or explain in terms of why a particular output was arrived at. <br /><br />
  In the image and video world, these advancements were translated by converting images to matrices, and a lot of linear algebra, convolutional neural networks and pre-trained residual learners later object detection, facial recognition was no big deal at all. 
  In the natural language modeling world, words were tokenized and represented as vectors of numbers for computers to understand, and then similar to number modeling neural networks entered this sphere as well and revolutionized it. 
  Next came transformers, an innovation in neural network architecture, which gave special attention to parts of the training text to extract meaning, thus understanding semantics. More enhancements to transformers, vectors represented as embeddings and the fusion of these with some general architecture patterns(for error reduction) like mixture-of-experts gave us ChatGPT. <br /><br />
  And the floodgates opened.<br /><br />
</p>
<p>
  Turing test passers, smarter chat bots, writers, personas, web developers, digital artists, musicians, therapists, entrepreneurs, a whole universe of AI opened up from the hype of one startup's chatty bot. Most likely because it didn't feel like a non-human - there were sparks of reasoning. There is immense potential in this general purpose technology, which it truly is and will impact most industries on the planet. But potential can be directed both positively and negatively with huge promise and concern at the same time. And now that so much attention, mine included, is at this one technology I want to ponder over the many heads of this creature - the fields impacted, some thoughts on where we might be going with this new, kinda smart friend of ours.
</p><br />

<br/>
<p>
  <b>Reference</b>
  <ul>
      <li>
          <a href="https://www.sigmacomputing.com/resources/learn/what-is-time-series-analysis" target="_blank">Introductory resource</a>
      </li>
      <li>
        Images: Bing (Dall-E)
      </li>
  </ul>
</p>